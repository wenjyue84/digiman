{
  "productName": "Rainbow AI Testing, Bug Fixes & Enhancements Phase 5",
  "branchName": "ralph/live-chat-enhancements",
  "overview": "Phase 5: 18 user stories across 5 phases \u00e2\u20ac\u201d fix broken features (test history, image attachments, tags/unit filters, contact details, AI notes), improve UI (KB tester, AI model consolidation, staff name menu), strengthen testing infrastructure (check-in suite, multi-turn workflow tests, programmatic runner), add capsule conflict resolution workflow, and update documentation. All changes within RainbowAI/ module only. Cross-cutting: regression tests for every change, agent-browser verification for UI changes.",
  "goals": [
    "Fix all 8 broken UI features (test history, pipeline test, image attachments, scenario count, button overlap, tags/unit filters, Set button, AI notes)",
    "Consolidate AI model settings into one location with OCR model support",
    "Build check-in process test suite with 10+ edge cases and multi-turn workflow tests",
    "Add capsule conflict detection and LLM-powered resolution workflow with operator approval",
    "Ensure zero regressions with comprehensive regression tests for every change"
  ],
  "userStories": [
    {
      "id": "US-001",
      "title": "Fix Quick Test History showing nothing",
      "priority": 1,
      "description": "As a tester, I want the Test History in #chat-simulator/quick-test to display previous test results so I can track my testing progress. History is managed by autotest-history.js module (localStorage keys: rainbow-autotest-history, rainbow-imported-reports). The modular refactor likely broke the save-after-test or render logic.",
      "acceptanceCriteria": [
        "Quick Test History modal shows previous test results when opened",
        "Test results persisted to localStorage keys 'rainbow-autotest-history' and 'rainbow-imported-reports'",
        "Each test run saved with: date, pass/fail/warning counts, pass rate",
        "History survives page refresh; auto-purge keeps max 20 entries",
        "Import mechanism loads reports from /api/rainbow/autotest/reports endpoint",
        "Regression test verifies history persistence across page loads",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "History module: RainbowAI/src/public/js/modules/autotest-history.js (state: autotestHistory array, importedReports array)",
        "UI rendering: RainbowAI/src/public/js/modules/autotest-ui.js (showAutotestHistory() renders list, loadHistoricalReport(id) restores)",
        "Also in: RainbowAI/src/public/js/modules/chat-send.js (line 17: QT_HISTORY_KEY, line 42: showQuickTestHistory())",
        "HTML: RainbowAI/src/public/templates/tabs/chat-simulator.html (line 241: button, line 287: modal)",
        "Auto-import: loadImportedReports() scans /api/rainbow/autotest/reports on page load",
        "Check if showAutotestHistory() in autotest-ui.js properly reads from autotest-history.js state"
      ],
      "dependencies": [],
      "estimatedComplexity": "small",
      "passes": true
    },
    {
      "id": "US-002",
      "title": "Fix 5 issues in message-pipeline.test.ts",
      "priority": 2,
      "description": "As a developer, I want message-pipeline.test.ts to pass all assertions correctly. The file EXISTS at RainbowAI/src/assistant/__tests__/message-pipeline.test.ts but has 5 identified issues: (1) incomplete error handling test, (2) truncation logic mismatch, (3) missing mock return values, (4) no prompt injection coverage, (5) static mock values making tests non-representative.",
      "acceptanceCriteria": [
        "message-pipeline.test.ts runs successfully via Vitest with all assertions passing",
        "Error handling test (line ~418) correctly tests whether processAndSend throws or catches",
        "Truncation test (line ~431) matches actual input-validator.ts behavior (verify if '...' is appended)",
        "callAPI mock returns realistic response objects instead of empty objects",
        "Prompt injection sanitization test added (verify testing-preview.ts lines 36-71 logic)",
        "classifyAndRespond mock uses varied intents per scenario instead of always 'pricing'",
        "Regression test verifies test runner execution works",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors"
      ],
      "technicalNotes": [
        "Test file: RainbowAI/src/assistant/__tests__/message-pipeline.test.ts (EXISTS \u00e2\u20ac\u201d uses Vitest)",
        "Also exists: RainbowAI/src/assistant/__tests__/language-resolution.test.ts (unit tests for language detection)",
        "Issue 1 (line ~418): Test expects rejects.toThrow() but comment says caller catches \u00e2\u20ac\u201d verify actual behavior",
        "Issue 2 (line ~431): Expects 'a'.repeat(2000) + '...' \u00e2\u20ac\u201d check if input-validator.ts appends ellipsis or just truncates",
        "Issue 3: callAPI mock returns {} as any \u00e2\u20ac\u201d should return { content, usage: { prompt_tokens, completion_tokens } }",
        "Issue 4 (line ~436): XSS test sends <script> but expects .continue = true \u00e2\u20ac\u201d need to verify sanitization in testing-preview.ts",
        "Issue 5: classifyAndRespond always returns 'pricing' \u00e2\u20ac\u201d make mock return different intents based on input message",
        "Testing UI: RainbowAI/src/public/templates/tabs/testing.html + RainbowAI/src/public/js/modules/testing.js"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": true
    },
    {
      "id": "US-003",
      "title": "Fix image attachment 'not found' in Quick Replies",
      "priority": 3,
      "description": "As a staff member, I want to attach images to quick replies in #responses/quick-replies without getting a 'not found' error so I can include visual content (maps, menus, room photos) in predefined responses.",
      "acceptanceCriteria": [
        "Attaching an image in #responses/quick-replies works without 'not found' error",
        "Image uploads successfully to server storage directory",
        "Image preview displays in the quick reply editor after upload",
        "Saved image URL is valid and accessible via HTTP GET",
        "Regression test for image upload endpoint (POST and GET)",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Quick replies CRUD: RainbowAI/src/public/js/modules/responses-crud.js (line 412: fetch('/api/rainbow/knowledge/upload-image', { method: 'POST', body: formData }))",
        "ROOT CAUSE: Backend endpoint /api/rainbow/knowledge/upload-image returns 404 \u00e2\u20ac\u201d not implemented",
        "Backend route file: RainbowAI/src/routes/admin/knowledge-base.ts \u00e2\u20ac\u201d needs upload-image handler",
        "FIX: Add POST /knowledge/upload-image with multer middleware for multipart file upload",
        "Endpoint should: accept file, store to uploads/ directory, return { imageUrl: '/path/to/image' }",
        "Also need: create RainbowAI/uploads/ directory, add Express static middleware for /uploads/ prefix"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-004",
      "title": "Fix autotest suite scenario count (hardcoded 58, actual 121)",
      "priority": 4,
      "description": "As a tester, I want the autotest suite count to dynamically reflect the actual number of test scenarios. Currently hardcoded as '58 scenarios across 6 guest journey phases' but actual count is 121 scenarios (100 single-turn + 21 workflow) across 9 categories.",
      "acceptanceCriteria": [
        "Scenario count in #chat-simulator updates dynamically from AUTOTEST_SCENARIOS.length (currently 121)",
        "Count updates automatically when scenarios are added or removed",
        "Hardcoded '58 scenarios' replaced with dynamic span in all HTML templates",
        "Category count also updates dynamically (currently 9: general, pre-arrival, arrival, during-stay, checkout, post-checkout, workflow-complete, conversation, sentiment)",
        "Regression test verifies count matches actual scenario array length",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Hardcoded: RainbowAI/src/public/templates/tabs/chat-simulator.html (line 37: '58 scenarios across 6 guest journey phases')",
        "Also hardcoded: RainbowAI/src/public/templates/tabs/preview.html (line 15)",
        "Scenario sources: autotest-scenarios-single.js (100) + autotest-scenarios-workflow.js (21) = 121 total",
        "Aggregator: RainbowAI/src/public/js/data/autotest-scenarios.js (combines SINGLE_TURN_SCENARIOS + WORKFLOW_SCENARIOS)",
        "Dynamic counting exists: RainbowAI/src/public/js/modules/autotest-ui.js (lines 353-355) but HTML overrides it",
        "Fix: Replace hardcoded text with <span id='scenario-count'>--</span> and <span id='phase-count'>--</span>, populate on load"
      ],
      "dependencies": [],
      "estimatedComplexity": "small",
      "passes": false
    },
    {
      "id": "US-005",
      "title": "Fix button overlap (delete/fullscreen)",
      "priority": 5,
      "description": "As a staff member, I want all buttons in the dashboard to be properly positioned without overlapping so I can click them reliably. Delete and fullscreen buttons currently overlap in some panels.",
      "acceptanceCriteria": [
        "Delete and fullscreen buttons do not overlap in any view",
        "All action buttons have minimum 8px gap between them",
        "Buttons are clickable without triggering adjacent buttons",
        "Fix applies across all tabs where overlap occurs (test results, KB editor, etc.)",
        "Regression test for button layout spacing",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Likely in autotest result cards or KB editor panels",
        "Check CSS: RainbowAI/src/public/css/rainbow-livechat-core.css",
        "Check CSS: RainbowAI/src/public/css/rainbow-livechat-ui.css",
        "May need gap, margin, or z-index fixes on absolute-positioned button groups",
        "Use agent-browser screenshots to identify exact overlapping elements"
      ],
      "dependencies": [],
      "estimatedComplexity": "small",
      "passes": false
    },
    {
      "id": "US-006",
      "title": "Fix Tags and Unit filter buttons in Live Chat",
      "priority": 6,
      "description": "As a staff member, I want the Tags and Unit filter buttons in #live-chat left pane to work \u00e2\u20ac\u201d clicking Unit should show all existing units, clicking Tags should show all existing tags, and selecting one should filter conversations.",
      "acceptanceCriteria": [
        "Clicking 'Unit' button shows dropdown of all existing units from capsule cache",
        "Clicking 'Tags' button shows dropdown of all existing tags from tags API",
        "Selecting a unit/tag filters conversation list correctly",
        "Dropdown closes when clicking outside",
        "Clear filter restores full conversation list",
        "Multiple tags can be selected simultaneously",
        "Regression test for filter dropdown rendering and filtering logic",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Filter code exists: RainbowAI/src/public/js/modules/live-chat-panels.js (lines 773-883: _renderTagFilterDropdown, _renderUnitFilterDropdown)",
        "Core filtering: RainbowAI/src/public/js/modules/live-chat-core.js (lines 433-449)",
        "HTML: RainbowAI/src/public/templates/tabs/live-chat.html (lines 111-125: tag/unit filter buttons with onclick handlers)",
        "Dropdown elements: lc-tag-filter-dropdown, lc-unit-filter-dropdown",
        "Button elements: lc-tag-filter-btn, lc-unit-filter-btn (onclick=lcToggleTagFilter/lcToggleUnitFilter)",
        "Tags API: GET /api/rainbow/tags (RainbowAI/src/routes/admin/tags.ts)",
        "Capsules API: GET /api/rainbow/capsules (RainbowAI/src/routes/admin/capsules.ts)",
        "Click outside: RainbowAI/src/public/js/modules/live-chat.js (lines 265-276)",
        "ROOT CAUSE: $.contactTagsMap and $.contactUnitsMap not populated \u00e2\u20ac\u201d loadContactTagsMap() and loadContactUnitsMap() not called early enough in initialization",
        "FIX: Ensure loadContactTagsMap(), loadContactUnitsMap(), loadCapsuleUnits() are called in loadLiveChat() before displaying chat list"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-007",
      "title": "Fix Payment Reminder 'Set' button (Failed Not found)",
      "priority": 7,
      "description": "As a staff member, I want the 'Set' button for payment reminders in #live-chat contact details to work without showing 'Failed Not found' so I can schedule payment reminders for guests. The frontend calls POST /payment-reminders but this endpoint is missing from the backend routes.",
      "acceptanceCriteria": [
        "Clicking 'Set' in payment reminder section saves without 'Failed Not found' error",
        "POST /api/rainbow/payment-reminders endpoint exists and accepts { phone, dueDate, autoSend }",
        "Payment reminder data persisted to storage (JSON file with atomic write)",
        "Auto-send checkbox controls whether chase message is sent automatically on due date",
        "Success toast shown after saving reminder",
        "Regression test for payment reminder endpoint (POST and GET)",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Frontend call: RainbowAI/src/public/js/modules/live-chat-panels.js (lines 1500-1526: lcSetPaymentReminder())",
        "Frontend calls: fetch('/api/rainbow/payment-reminders', { method: 'POST', body: { phone, dueDate, autoSend } })",
        "HTML: RainbowAI/src/public/templates/tabs/live-chat.html (lines 764-775: payment reminder form)",
        "Backend route file: RainbowAI/src/routes/admin/payment-reminders.ts \u00e2\u20ac\u201d check if it exists and is mounted in index.ts",
        "Root cause: POST /payment-reminders endpoint is NOT implemented or NOT mounted in routes/admin/index.ts",
        "Fix: Create or mount payment-reminders.ts route with POST handler that stores reminder data",
        "Storage: Use atomic JSON write pattern (config-store.ts) to persist reminders"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-008",
      "title": "Fix AI Notes truncation in Contact Details",
      "priority": 8,
      "description": "As a staff member, I want 'Generate by AI' notes in #live-chat contact details to show complete output without truncation so I can see the full AI-generated summary of the conversation.",
      "acceptanceCriteria": [
        "'Generate by AI' produces complete, untruncated output",
        "Notes textarea auto-expands to show full generated text",
        "No max-height or overflow:hidden cutting off content in CSS",
        "AI provider max_tokens is sufficient for full summary (check >= 500)",
        "Regression test for notes generation completeness",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "AI notes function: RainbowAI/src/public/js/modules/live-chat-panels.js (lines 1322-1353: generateAINotes())",
        "Frontend auto-expand code at lines 1341-1343: textarea.style.height = 'auto'; textarea.style.height = textarea.scrollHeight + 'px';",
        "API: POST /conversations/:phone/generate-notes in RainbowAI/src/routes/admin/conversations.ts (line 668: chatWithFallback(messages, 600, 0.5) \u00e2\u20ac\u201d 600 tokens is sufficient)",
        "ROOT CAUSE: CSS .lc-field-textarea has max-height: 120px which overrides the JS auto-expand",
        "CSS location: RainbowAI/src/public/css/rainbow-livechat-ui.css (line ~511: .lc-field-textarea { max-height: 120px })",
        "FIX: Remove or significantly increase max-height on .lc-field-textarea, or add specific override for notes textarea"
      ],
      "dependencies": [],
      "estimatedComplexity": "small",
      "passes": false
    },
    {
      "id": "US-009",
      "title": "Build KB Accuracy Tester at top of Knowledge Base page",
      "priority": 9,
      "description": "As a staff member, I want a KB Accuracy Tester at the top of #responses/knowledge-base so I can test how well the KB retrieves relevant content for guest questions. Layout should be similar to #chat-simulator/quick-test. NOTE: This tester does NOT exist yet \u00e2\u20ac\u201d the Understanding tab has an intent classification test console, but there is no KB retrieval accuracy tester. It must be built from scratch.",
      "acceptanceCriteria": [
        "New KB Accuracy Tester section built at the top of Knowledge Base page",
        "Input field to type a guest question + Test button",
        "Results show: which KB files were loaded, relevance score, AI response using KB content",
        "Layout similar to quick-test: input + results above KB file management content",
        "Existing KB management content (file list, editor) below the tester",
        "No functionality regression in KB file editing",
        "Regression test for KB tester endpoint and UI",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "KB Accuracy Tester does NOT exist yet \u00e2\u20ac\u201d must be built from scratch",
        "KB template: RainbowAI/src/public/templates/tabs/responses.html (Knowledge Base sub-tab)",
        "KB modules: RainbowAI/src/public/js/modules/knowledge.js and kb-editor.js",
        "KB route: RainbowAI/src/routes/admin/knowledge-base.ts",
        "New endpoint needed: POST /api/rainbow/knowledge-base/test \u00e2\u20ac\u201d accepts question, returns loaded KB files + AI response",
        "Backend: Use knowledge-base.ts guessTopicFiles() to find relevant files, then ai-client.ts to generate response",
        "The Understanding tab has an intent test console \u00e2\u20ac\u201d use similar UI pattern but for KB retrieval"
      ],
      "dependencies": [],
      "estimatedComplexity": "small",
      "passes": false
    },
    {
      "id": "US-010",
      "title": "Token usage details in KB Accuracy Tester",
      "priority": 10,
      "description": "As a staff member, I want detailed token usage breakdown in the KB Accuracy Tester (built in US-009) so I can understand which parts consume the most tokens and optimize accordingly. This helps me figure out how to reduce token cost per question.",
      "acceptanceCriteria": [
        "KB test results show: input tokens, output tokens, total tokens",
        "Show KB context tokens separately (how many tokens the loaded KB content consumes)",
        "Show system prompt token count",
        "Show user message token count",
        "Breakdown table: system_prompt + kb_context + user_message = total input tokens",
        "Show which KB files were loaded and their individual token sizes",
        "Regression test for token data in test response",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Depends on US-009 (KB Accuracy Tester must exist first)",
        "AI client: RainbowAI/src/assistant/ai-client.ts \u00e2\u20ac\u201d returns usage data from provider response",
        "KB test endpoint: POST /api/rainbow/knowledge-base/test (created in US-009)",
        "Token estimation: Use tiktoken or simple char/4 approximation for pre-send estimates",
        "For each loaded KB file: calculate approximate token count before sending to AI",
        "Display format: collapsible details panel below test result showing token breakdown table",
        "Provider usage field varies: OpenAI-compatible returns { prompt_tokens, completion_tokens, total_tokens }"
      ],
      "dependencies": [
        "US-009"
      ],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-011",
      "title": "Consolidate AI Model Settings with OCR model",
      "priority": 11,
      "description": "As a staff member, I want all AI model settings combined at #settings/ai-models (merging settings from #understanding/t4), with a read-only link in T4, and a new OCR LLM model setting (default: Google Gemini 2.5 Flash) for passport/IC image extraction.",
      "acceptanceCriteria": [
        "All AI model settings from #settings/ai-models and #understanding/t4 combined at #settings/ai-models",
        "#understanding/t4 shows read-only display of current T4 model with 'Edit in Settings \u00e2\u2020\u2019 AI Models' link",
        "New OCR LLM model setting added with default Google Gemini 2.5 Flash",
        "OCR model selectable from existing provider dropdown list",
        "Settings saved to settings.json atomically via config-store",
        "Regression test for settings save/load with new OCR field",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Settings AI models module: RainbowAI/src/public/js/modules/settings-ai-models.js (546 lines \u00e2\u20ac\u201d drag-drop reorder, speed testing)",
        "Settings template: RainbowAI/src/public/templates/tabs/settings.html",
        "Understanding template: RainbowAI/src/public/templates/tabs/understanding.html (756 lines \u00e2\u20ac\u201d T4 section has LLM model selector, fallback list, max_tokens, temperature, system prompt)",
        "Understanding module: RainbowAI/src/public/js/modules/understanding.js",
        "Settings data: RainbowAI/src/assistant/data/settings.json (17 providers, routing_mode.classifyProvider is the T4 model config key)",
        "T4 model structure in understanding.html: select dropdown for LLM model, fallback model list, max_tokens slider, temperature slider, system prompt editor",
        "Add ocr_provider field to settings.json: { id: 'google-gemini-flash', model: 'gemini-2.5-flash' }",
        "Consolidation: Move T4 model selector + fallback + max_tokens + temperature from understanding.html into settings-ai-models.js",
        "Replace T4 section with read-only display showing current model name + link to #settings/ai-models"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-012",
      "title": "Move Staff name to 3-dot vertical menu",
      "priority": 12,
      "description": "As a staff member, I want the Staff name moved from the header area into the 3-dot vertical menu in #live-chat to reduce header clutter. The edit-to-change-name functionality should remain.",
      "acceptanceCriteria": [
        "Staff name no longer shows directly in the header beside connection status",
        "Staff name accessible via the 3-dot menu (vertical ellipsis icon)",
        "3-dot menu shows 'Staff: [name]' with click-to-edit option",
        "Staff name persists after editing (saved to settings.json)",
        "Regression test for staff name save/load from menu",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "Staff name in header: RainbowAI/src/public/js/modules/live-chat-core.js",
        "Settings: RainbowAI/src/assistant/data/settings.json (field: staffName, default: 'Staff')",
        "Live chat template: RainbowAI/src/public/templates/tabs/live-chat.html",
        "3-dot menu: existing vertical ellipsis icon in the header area near 'New chat' button",
        "Move the staff name element from header into the 3-dot dropdown menu items"
      ],
      "dependencies": [],
      "estimatedComplexity": "small",
      "passes": false
    },
    {
      "id": "US-013",
      "title": "Add Check-in Process test suite",
      "priority": 13,
      "description": "As a tester, I want a dedicated 'Check-in Process' test suite in the Run All dropdown that tests the complete check-in workflow with 10+ edge cases from easy to hard, including different languages and error scenarios.",
      "acceptanceCriteria": [
        "New 'Check-in Process' option in Run All test suite dropdown",
        "10+ scenarios ordered easy to hard: basic inquiry, specific date, multiple guests, capsule preference, special requests, late arrival, early arrival, fully booked, wrong date format, multilingual (en/ms/zh)",
        "Tests run programmatically and report pass/fail per scenario",
        "Results include: matched intent, confidence, response quality assessment",
        "Failed tests logged with details for user story generation",
        "Regression test for test suite runner functionality",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors"
      ],
      "technicalNotes": [
        "Autotest scenarios: RainbowAI/src/public/js/modules/autotest-scenarios.js",
        "Autotest execution: RainbowAI/src/public/js/modules/autotest-execution.js",
        "Autotest UI: RainbowAI/src/public/js/modules/autotest-ui.js",
        "Add scenarios to autotest-scenarios.js with category 'check-in-process'",
        "Run All dropdown: extend with new test suite filter option",
        "Check-in intent keywords: RainbowAI/src/assistant/data/intent-keywords.json"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-014",
      "title": "Run All tests programmatically and generate user stories",
      "priority": 14,
      "description": "As a developer, I want to run all autotest scenarios programmatically via API and get structured results so failed tests can be auto-converted to user stories for the next iteration.",
      "acceptanceCriteria": [
        "API endpoint POST /api/rainbow/testing/run-all triggers all tests",
        "Returns JSON: { total, passed, failed, results: [{ scenario, expected, actual, confidence, error }] }",
        "API endpoint GET /api/rainbow/testing/generate-stories converts failures to prd.json format",
        "Generated stories include: title from failure, acceptance criteria from expected behavior",
        "Can filter by test suite: ?suite=check-in-process or ?suite=workflow",
        "Regression test for programmatic test runner",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors"
      ],
      "technicalNotes": [
        "Testing route: RainbowAI/src/routes/admin/testing.ts",
        "Autotest execution: RainbowAI/src/public/js/modules/autotest-execution.js",
        "Need backend version of test execution (frontend runs in browser, backend needs to call pipeline directly)",
        "Use message-router.ts processMessage() to simulate each test scenario",
        "Save results to RainbowAI/reports/autotest/ directory"
      ],
      "dependencies": [],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-015",
      "title": "Enhance multi-turn workflow autotest to cover ALL turns",
      "priority": 15,
      "description": "As a tester, I want workflow autotests to simulate complete multi-turn conversations where the test answers ALL questions in a workflow (not just the first one). 21 workflow scenarios already exist in autotest-scenarios-workflow.js but some only test 1 turn. Enhance all scenarios to cover the full guest journey through every workflow step.",
      "acceptanceCriteria": [
        "All 21 existing workflow scenarios enhanced to include ALL turns (not just first message)",
        "Each turn sends realistic guest response to the workflow question",
        "Test verifies AI asks correct next question after each answer",
        "Tests cover: check-in workflow (all steps), complaint workflow, booking workflow",
        "Test validates workflow completion (final confirmation message)",
        "Results show per-turn pass/fail, not just per-scenario",
        "Regression test for multi-turn execution engine",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors"
      ],
      "technicalNotes": [
        "21 workflow scenarios ALREADY EXIST: RainbowAI/src/public/js/modules/autotest-scenarios-workflow.js",
        "Existing format: { id, name, category, messages: [{text}], validate: [{turn, rules}] }",
        "Example: 'workflow-booking-payment-full' has 6 turns with per-turn validation rules",
        "Execution engine: autotest-execution.js sends each message sequentially to /preview/chat with accumulated history",
        "Workflow state tracking: testing-preview.ts uses previewWorkflowStates Map (key = firstMessage::history.length)",
        "Issue: Some scenarios only define 1 message/turn but workflows need 3-6 turns to complete",
        "Fix: Add full turn sequences (messages + validate arrays) to scenarios that currently only test first turn",
        "Optimal concurrency: 2 workers (69.6% pass rate); 4+ causes rate limiting"
      ],
      "dependencies": [],
      "estimatedComplexity": "large",
      "passes": false
    },
    {
      "id": "US-016",
      "title": "Create user stories from autotest errors",
      "priority": 16,
      "description": "As a developer, after implementing multi-turn workflow tests and check-in suite, I want to run the full test suite and auto-generate user stories from any failures to feed the next development iteration.",
      "acceptanceCriteria": [
        "Full autotest suite runs including multi-turn workflow tests and check-in suite",
        "All failures collected with: scenario name, expected vs actual, confidence, error details",
        "User stories auto-generated in prd.json format from each failure category",
        "Generated stories appended to prd.json or output as separate JSON file",
        "At least 5 meaningful user stories generated from real test failures",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors"
      ],
      "technicalNotes": [
        "Depends on US-014 (programmatic runner) and US-015 (multi-turn tests)",
        "Use POST /api/rainbow/testing/run-all from US-014",
        "Use GET /api/rainbow/testing/generate-stories from US-014 to convert",
        "Output to: RainbowAI/reports/autotest/generated-stories.json",
        "May also add generated stories directly to prd.json using a merge script"
      ],
      "dependencies": [
        "US-014",
        "US-015"
      ],
      "estimatedComplexity": "medium",
      "passes": false
    },
    {
      "id": "US-017",
      "title": "Capsule Conflict Detection and Resolution Workflow",
      "priority": 17,
      "description": "As a capsule operator, I want Rainbow AI to detect capsule occupancy conflicts (guest finds someone in their assigned capsule), notify the operator via WhatsApp, use LLM to suggest resolution, and execute approved changes. Covers: wrong updates, unauthorized capsule switches, and unknown occupants.",
      "acceptanceCriteria": [
        "Rainbow AI detects capsule conflict from guest messages (e.g. 'someone is in my capsule')",
        "New intent 'capsule_conflict' added with keywords and examples in en/ms/zh",
        "AI checks capsule assignment data via dashboard API (port 5000 /api/capsules)",
        "AI sends WhatsApp notification to capsule operator with conflict details",
        "AI uses LLM to analyze situation and suggest resolution actions",
        "For capsule switch: AI suggests updating both capsule assignments with operator approval",
        "For unknown person: AI suggests physical inspection and waits for operator decision",
        "Operator can approve/reject via WhatsApp reply (simple 'yes'/'no' or '1'/'2' options)",
        "After approval: AI updates capsule assignment in system and confirms to guest",
        "All conflict events logged to conversation history for audit",
        "Regression tests for: intent detection, operator notification, approval flow",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors"
      ],
      "technicalNotes": [
        "New intent: Add capsule_conflict to intent-keywords.json and intent-examples.json",
        "Routing: Add capsule_conflict to routing.json with action escalate_capsule_conflict",
        "Capsule data: RainbowAI/src/lib/capsule-cache.ts for checking assignments via HTTP to port 5000",
        "Staff notification: RainbowAI/src/lib/whatsapp/instance.ts sendMessage to operator phone",
        "LLM analysis: RainbowAI/src/assistant/ai-client.ts with capsule conflict analysis prompt",
        "Approval flow: Store pending approvals in RainbowAI/data/pending-approvals.json (atomic write)",
        "Operator reply detection: Listen for staff phone messages in message-router.ts, match pending approval ID",
        "Staff phones: settings.json \u00e2\u2020\u2019 staff.phones array",
        "Multi-language: All messages to guest and operator need en/ms/zh variants",
        "New pipeline stage or action handler needed in action-dispatch.ts for escalate_capsule_conflict"
      ],
      "dependencies": [],
      "estimatedComplexity": "large",
      "passes": false
    },
    {
      "id": "US-018",
      "title": "Update User Guide and Developer Guide",
      "priority": 18,
      "description": "As a staff member or developer, I want the guides at #help to reflect all Phase 5 changes \u00e2\u20ac\u201d bug fixes, new features, consolidated settings, test infrastructure improvements, and capsule conflict workflow.",
      "acceptanceCriteria": [
        "User guide updated: KB Accuracy Tester location, consolidated AI settings, OCR model, capsule conflict handling",
        "Developer guide updated: new test suites, programmatic testing API, multi-turn test format, new intents/routes",
        "Bug fixes mentioned in a changelog or 'Recent Changes' section",
        "Staff name moved to menu documented in user guide",
        "Capsule conflict workflow documented with operator instructions",
        "TypeScript compiles with zero errors",
        "Server starts and dashboard loads without errors",
        "Verify in browser using agent-browser"
      ],
      "technicalNotes": [
        "User guide: RainbowAI/src/public/templates/tabs/help-user-guide.html",
        "Developer guide: RainbowAI/src/public/templates/tabs/help-developer-guide.html",
        "Help module: RainbowAI/src/public/js/modules/help.js",
        "Depends on all other stories being complete",
        "Include links to relevant settings pages and test tools"
      ],
      "dependencies": [
        "US-001",
        "US-002",
        "US-003",
        "US-004",
        "US-005",
        "US-006",
        "US-007",
        "US-008",
        "US-009",
        "US-010",
        "US-011",
        "US-012",
        "US-013",
        "US-014",
        "US-015",
        "US-016",
        "US-017"
      ],
      "estimatedComplexity": "medium",
      "passes": false
    }
  ],
  "technicalContext": {
    "affectedAreas": [
      "RainbowAI/src/public/js/modules/chat-send.js",
      "RainbowAI/src/public/js/modules/autotest-scenarios.js",
      "RainbowAI/src/public/js/modules/autotest-scenarios-workflow.js",
      "RainbowAI/src/public/js/modules/autotest-execution.js",
      "RainbowAI/src/public/js/modules/autotest-ui.js",
      "RainbowAI/src/public/js/modules/autotest-history.js",
      "RainbowAI/src/public/js/modules/workflow-testing.js",
      "RainbowAI/src/public/js/modules/testing.js",
      "RainbowAI/src/public/js/modules/responses-crud.js",
      "RainbowAI/src/public/js/modules/live-chat-panels.js",
      "RainbowAI/src/public/js/modules/live-chat-core.js",
      "RainbowAI/src/public/js/modules/live-chat-actions.js",
      "RainbowAI/src/public/js/modules/live-chat.js",
      "RainbowAI/src/public/js/modules/settings-ai-models.js",
      "RainbowAI/src/public/js/modules/llm-settings.js",
      "RainbowAI/src/public/js/modules/understanding.js",
      "RainbowAI/src/public/js/modules/knowledge.js",
      "RainbowAI/src/public/js/modules/kb-editor.js",
      "RainbowAI/src/public/js/modules/help.js",
      "RainbowAI/src/public/js/features/workflow-tester.js",
      "RainbowAI/src/public/js/module-chunks/chat-simulator-chunk.js",
      "RainbowAI/src/public/templates/tabs/chat-simulator.html",
      "RainbowAI/src/public/templates/tabs/preview.html",
      "RainbowAI/src/public/templates/tabs/settings.html",
      "RainbowAI/src/public/templates/tabs/live-chat.html",
      "RainbowAI/src/public/templates/tabs/testing.html",
      "RainbowAI/src/public/templates/tabs/help-user-guide.html",
      "RainbowAI/src/public/templates/tabs/help-developer-guide.html",
      "RainbowAI/src/public/css/rainbow-livechat-core.css",
      "RainbowAI/src/public/css/rainbow-livechat-ui.css",
      "RainbowAI/src/routes/admin/testing.ts",
      "RainbowAI/src/routes/admin/testing-preview.ts",
      "RainbowAI/src/routes/admin/templates.ts",
      "RainbowAI/src/routes/admin/tags.ts",
      "RainbowAI/src/routes/admin/capsules.ts",
      "RainbowAI/src/routes/admin/conversations.ts",
      "RainbowAI/src/routes/admin/knowledge-base.ts",
      "RainbowAI/src/routes/admin/index.ts",
      "RainbowAI/src/assistant/data/settings.json",
      "RainbowAI/src/assistant/data/intent-keywords.json",
      "RainbowAI/src/assistant/data/intent-examples.json",
      "RainbowAI/src/assistant/message-router.ts",
      "RainbowAI/src/assistant/ai-client.ts",
      "RainbowAI/src/assistant/config-store.ts",
      "RainbowAI/src/lib/capsule-cache.ts",
      "RainbowAI/src/lib/whatsapp/instance.ts"
    ],
    "newFiles": [
      "RainbowAI/data/pending-approvals.json"
    ],
    "testingStrategy": "Regression tests for every change + programmatic autotest runner (US-014) + multi-turn workflow tests (US-015) + agent-browser visual verification for UI changes",
    "rollbackPlan": "git checkout HEAD -- RainbowAI/src/public/ RainbowAI/src/routes/ RainbowAI/src/assistant/ RainbowAI/src/lib/",
    "crossCuttingConcerns": {
      "regressionTests": "Every user story must include regression tests that verify the fix/feature works and existing features are not broken",
      "agentBrowserVerification": "All UI-affecting stories must be verified using agent-browser skill before marking complete",
      "importBoundaries": "RainbowAI/ must have ZERO imports from server/, client/, or shared/ \u00e2\u20ac\u201d HTTP fetch only for cross-module data",
      "atomicWrites": "All new JSON data files use config-store.ts atomic write pattern (.tmp then renameSync)"
    }
  }
}