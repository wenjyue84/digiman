{
  "ai": {
    "nvidia_model": "moonshotai/kimi-k2.5",
    "nvidia_base_url": "https://integrate.api.nvidia.com/v1",
    "groq_model": "llama-3.3-70b-versatile",
    "max_classify_tokens": 100,
    "max_chat_tokens": 500,
    "classify_temperature": 0.05,
    "chat_temperature": 0.7,
    "providers": [
      {
        "id": "google-gemini-flash",
        "name": "Google Gemini 2.5 Flash",
        "description": "Google's latest Gemini 2.5 Flash model (stable, June 2025). Ultra-fast, multimodal, 1M token context, and excellent at multilingual understanding. Native Google Translate integration for superior casual/slang comprehension. Best for real-time WhatsApp chat.",
        "type": "google-gemini",
        "api_key_env": "GEMINI_API_KEY",
        "base_url": "https://generativelanguage.googleapis.com/v1beta",
        "model": "gemini-2.5-flash",
        "enabled": true,
        "priority": 0,
        "available": true
      },
      {
        "id": "ollama-gemini-flash",
        "name": "Ollama Gemini 3 Flash",
        "description": "Google's speed-optimized frontier model. Trained on Google Translate corpus â€” excels at understanding casual/slang multilingual input ('eh bro wifi pass apa'). Different architecture from Llama/Qwen/DeepSeek, so may succeed when others fail. Free via Ollama cloud.",
        "type": "ollama",
        "api_key_env": "",
        "base_url": "http://localhost:11434/v1",
        "model": "gemini-3-flash-preview:cloud",
        "enabled": true,
        "priority": 1,
        "available": true
      },
      {
        "id": "groq-llama",
        "name": "Groq Llama 3.3 70B",
        "description": "Balanced quality/speed (280 tok/s). Meta's workhorse 70B model with 131K context. Reliable for chat responses, good multilingual understanding. Proven stable fallback.",
        "type": "groq",
        "api_key_env": "GROQ_API_KEY",
        "base_url": "https://api.groq.com/openai/v1",
        "model": "llama-3.3-70b-versatile",
        "enabled": true,
        "priority": 2,
        "available": true
      },
      {
        "id": "ollama-local",
        "name": "Ollama GPT-OSS 20B",
        "description": "Fastest cloud model via Ollama (~3s). GPT-4 class quality with visible chain-of-thought. No rate limits, no API key needed. Best default for all tasks.",
        "type": "ollama",
        "api_key_env": "",
        "base_url": "http://localhost:11434/v1",
        "model": "gpt-oss:20b-cloud",
        "enabled": true,
        "priority": 3,
        "available": true
      },
      {
        "id": "groq-llama-8b",
        "name": "Groq Llama 3.1 8B Instant",
        "description": "Ultra-fast (560 tok/s) â€” fastest on Groq. Purpose-built for latency-critical apps. Small but reliable for structured JSON intent classification. Best as a quick classification fallback.",
        "type": "groq",
        "api_key_env": "GROQ_API_KEY",
        "base_url": "https://api.groq.com/openai/v1",
        "model": "llama-3.1-8b-instant",
        "enabled": true,
        "priority": 4,
        "available": true
      },
      {
        "id": "groq-qwen3-32b",
        "name": "Groq Qwen3 32B",
        "description": "Alibaba's trilingual specialist (400 tok/s). Native Chinese tokenization (3x more efficient than Llama for CJK). Trained on substantial Malay/Indonesian corpus. Supports thinking mode. Best for Chinese and Malay guest conversations.",
        "type": "groq",
        "api_key_env": "GROQ_API_KEY",
        "base_url": "https://api.groq.com/openai/v1",
        "model": "qwen3-32b",
        "enabled": true,
        "priority": 5,
        "available": true
      },
      {
        "id": "ollama-deepseek-v3.2",
        "name": "Ollama DeepSeek V3.2",
        "description": "~685B MoE reasoning model. Successor to V3.1 with balanced compute allocation â€” spends more effort on hard sub-questions, less on easy ones. Better at following complex multi-rule system prompts. Free via Ollama cloud.",
        "type": "ollama",
        "api_key_env": "",
        "base_url": "http://localhost:11434/v1",
        "model": "deepseek-v3.2:cloud",
        "enabled": true,
        "priority": 6,
        "available": true
      },
      {
        "id": "ollama-qwen3-80b",
        "name": "Ollama Qwen3 80B",
        "description": "Alibaba's parameter-efficient 80B general model. Redesigned transformer for 80B quality with less compute. Natively bilingual Chinese/English with strong Malay. Upgrade from Qwen3 32B for harder multilingual queries. Free via Ollama cloud.",
        "type": "ollama",
        "api_key_env": "",
        "base_url": "http://localhost:11434/v1",
        "model": "qwen3-next:80b-cloud",
        "enabled": false,
        "priority": 7,
        "available": true
      },
      {
        "id": "groq-llama4-scout",
        "name": "Groq Llama 4 Scout 17B",
        "description": "Meta's newest Llama 4 (750 tok/s). First Llama with MoE â€” only ~4B params active per token despite 17B total. Near-8B speed with much better quality. Natively trained for multi-turn conversation. Best speed/quality ratio for chat.",
        "type": "groq",
        "api_key_env": "GROQ_API_KEY",
        "base_url": "https://api.groq.com/openai/v1",
        "model": "llama-4-scout-17b",
        "enabled": false,
        "priority": 8,
        "available": true
      },
      {
        "id": "groq-deepseek-r1",
        "name": "Groq DeepSeek R1 Distill 70B",
        "description": "70B model distilled from DeepSeek R1's 671B reasoning engine (~200 tok/s). Inherits chain-of-thought ability â€” naturally breaks complex problems into steps. Excels at multi-step logic (date calculations, price comparisons, booking availability). Best for complex guest queries.",
        "type": "groq",
        "api_key_env": "GROQ_API_KEY",
        "base_url": "https://api.groq.com/openai/v1",
        "model": "deepseek-r1-distill-llama-70b",
        "enabled": false,
        "priority": 9,
        "available": true
      },
      {
        "id": "moonshot-kimi",
        "name": "Moonshot Kimi 2.5",
        "description": "Moonshot AI's Kimi K2.5 (262K context). Supports reasoning, images, and video. Premium quality multimodal model for deep analysis. Requires Moonshot API key from platform.moonshot.ai.",
        "type": "openai-compatible",
        "api_key_env": "MOONSHOT_API_KEY",
        "base_url": "https://api.moonshot.ai/v1",
        "model": "kimi-k2.5",
        "enabled": false,
        "priority": 10,
        "available": true
      },
      {
        "id": "openrouter-qwen-32b",
        "name": "Qwen 2.5 32B (Free)",
        "description": "Alibaba's Qwen 2.5 32B - Strong reasoning, multilingual support, free tier",
        "type": "openai-compatible",
        "api_key_env": "OPENROUTER_API_KEY",
        "base_url": "https://openrouter.ai/api/v1",
        "model": "qwen/qwen-2.5-32b-instruct",
        "enabled": false,
        "priority": 11,
        "available": true
      },
      {
        "id": "openrouter-gemma-9b",
        "name": "Google Gemma 2 9B (Free)",
        "description": "Google's Gemma 2 9B IT - Efficient, instruction-tuned, free tier",
        "type": "openai-compatible",
        "api_key_env": "OPENROUTER_API_KEY",
        "base_url": "https://openrouter.ai/api/v1",
        "model": "google/gemma-2-9b-it:free",
        "enabled": false,
        "priority": 12,
        "available": true
      },
      {
        "id": "openrouter-llama-8b",
        "name": "Meta Llama 3.1 8B (Free)",
        "description": "Meta's Llama 3.1 8B - Fast, capable, free tier",
        "type": "openai-compatible",
        "api_key_env": "OPENROUTER_API_KEY",
        "base_url": "https://openrouter.ai/api/v1",
        "model": "meta-llama/llama-3.1-8b-instruct:free",
        "enabled": false,
        "priority": 13,
        "available": true
      },
      {
        "id": "openrouter-mistral-7b",
        "name": "Mistral 7B (Free)",
        "description": "Mistral AI's 7B model - Efficient, high quality, free tier",
        "type": "openai-compatible",
        "api_key_env": "OPENROUTER_API_KEY",
        "base_url": "https://openrouter.ai/api/v1",
        "model": "mistralai/mistral-7b-instruct:free",
        "enabled": false,
        "priority": 14,
        "available": true
      },
      {
        "id": "openrouter-phi-3",
        "name": "Microsoft Phi-3 Medium (Free)",
        "description": "Microsoft Phi-3 Medium - Compact but powerful, free tier",
        "type": "openai-compatible",
        "api_key_env": "OPENROUTER_API_KEY",
        "base_url": "https://openrouter.ai/api/v1",
        "model": "microsoft/phi-3-medium-128k-instruct:free",
        "enabled": false,
        "priority": 15,
        "available": true
      }
    ]
  },
  "routing_mode": {
    "splitModel": false,
    "classifyProvider": "groq-llama-8b",
    "tieredPipeline": true
  },
  "ocr_provider": {
    "id": "google-gemini-flash",
    "model": "gemini-2.5-flash",
    "description": "LLM model used for passport/IC image extraction (OCR). Google Gemini Flash recommended for its multimodal vision capabilities."
  },
  "system_prompt": "You are Rainbow, a friendly female AI assistant for Pelangi Capsule Hostel in Johor Bahru, Malaysia. You always clarify that you are an AI bot when introducing yourself. You help guests with check-in info, pricing, availability, bookings, and general hostel questions. Be warm, concise, and helpful. Reply in the same language as the guest (English, Malay, or Chinese). Keep responses under 300 characters when possible. Sign off with \"â€” Rainbow ðŸŒˆ\" on important messages. If unsure, suggest contacting staff.",
  "rate_limits": {
    "per_minute": 40,
    "per_hour": 200
  },
  "staff": {
    "phones": [
      "60167620815",
      "60127088789",
      "60103084289"
    ],
    "jay_phone": "60127088789",
    "alston_phone": "60167620815"
  },
  "conversation_management": {
    "enabled": true,
    "summarize_threshold": 6,
    "summarize_from_message": 1,
    "summarize_to_message": 5,
    "keep_verbatim_from": 6,
    "keep_verbatim_to": 20,
    "description": "After 10 messages, summarize messages 1-5 and keep 6-20 verbatim to reduce context overflow by ~50%"
  },
  "sentiment_analysis": {
    "enabled": true,
    "consecutive_threshold": 2,
    "cooldown_minutes": 30,
    "description": "Automatically detect frustrated users and escalate to staff when they send consecutive negative messages"
  },
  "failover": {
    "enabled": false,
    "heartbeatIntervalMs": 20000,
    "failoverThresholdMs": 60000,
    "handbackMode": "immediate",
    "handbackGracePeriodMs": 30000
  },
  "botAvatar": "ðŸ¤–",
  "prismaBot": {
    "model": "gemini-2.5-flash",
    "providerId": "google-gemini-flash",
    "systemPrompt": ""
  },
  "staffName": "Rachel",
  "response_modes": {
    "manual": {
      "description": "Show AI suggestions when 'Help me' clicked",
      "ai_help_provider": "groq-llama",
      "show_ai_suggestions": true
    },
    "copilot": {
      "description": "Auto-approve high-confidence responses for simple intents",
      "auto_approve_intents": [
        "greeting",
        "thanks",
        "wifi"
      ],
      "queue_timeout_minutes": 30,
      "auto_approve_confidence": 0.95
    },
    "description": "Global default response mode: autopilot (AI auto-sends), copilot (AI suggests, staff approves), or manual (staff writes, AI helps on request)",
    "default_mode": "autopilot"
  }
}