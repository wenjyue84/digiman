# Configuration Quick Reference

Visual summary of optimal configuration strategies. Print this page for quick reference.

---

## Guest Journey Phases

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GUEST JOURNEY TIMELINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  PRE-ARRIVAL          CHECK-IN           DURING STAY        CHECKOUT    â”‚
â”‚  (Days -7 to 0)      (Minutes 0-30)    (Hours 1-23)      (Hours 24-25) â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Booking    â”‚    â”‚ â€¢ Card issue â”‚  â”‚ â€¢ WiFi help  â”‚  â”‚ â€¢ Paymentâ”‚  â”‚
â”‚  â”‚ â€¢ Pricing    â”‚    â”‚ â€¢ Room info  â”‚  â”‚ â€¢ Complaint  â”‚  â”‚ â€¢ Status â”‚  â”‚
â”‚  â”‚ â€¢ Avail.     â”‚    â”‚ â€¢ Urgent Q.  â”‚  â”‚ â€¢ Directions â”‚  â”‚ â€¢ Processâ”‚  â”‚
â”‚  â”‚              â”‚    â”‚ â€¢ Escalate   â”‚  â”‚ â€¢ Orienting  â”‚  â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     Quality > Speed     Speed Critical     Balanced      Task-Focused   â”‚
â”‚                                                                           â”‚
â”‚                    POST-CHECKOUT                                         â”‚
â”‚                    (Days 0-14)                                           â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚                    â”‚ â€¢ Billing Q.  â”‚                                     â”‚
â”‚                    â”‚ â€¢ Lost items  â”‚                                     â”‚
â”‚                    â”‚ â€¢ Feedback    â”‚                                     â”‚
â”‚                    â”‚ â€¢ Sporadic    â”‚                                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚                      Low Volume                                          â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Context Sizing by Phase

```
PHASE              CLASSIFY  CHAT   TIMEOUT  CONFIDENCE  TEMPLATE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pre-Arrival        5 msgs    15 msg  3000ms   0.70       T2
Check-In           4 msgs    10 msgs 2000ms   0.60       T4  â† Urgent
During Stay       10 msgs    20 msgs 3000ms   0.80       T4
Checkout           8 msgs    15 msgs 2500ms   0.65       T3
Post-Checkout      8 msgs    15 msgs 4000ms   0.75       T1

KEY: More context = slower but more accurate
     Less context = faster but may miss nuance
```

---

## Rate Limits by Phase

```
PHASE          PER-MINUTE  PER-HOUR  URGENT  ESCALATE-ON
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pre-Arrival       10         50      No      Confusion (3+ unknown)
Check-In          30        100      YES     âš ï¸ Escalate < 0.40 confidence
During Stay       20         80      No      Repeated questions (3+)
Checkout          20         80      No      Unclear (2+ unknown)
Post-Checkout      5         20      No      Trend-based (2min decline)

Note: Staff are always exempt from rate limits
```

---

## Provider Selection

```
LANGUAGE    PREFERRED PROVIDER      FALLBACK            MULTILINGUAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
English     Groq Llama 70B         Ollama GPT-OSS      Generic
Malay       Groq Qwen3 32B  â­     Groq Llama 70B      Good
Chinese     Groq Qwen3 32B  â­     Ollama DeepSeek     Excellent
Code-Mix    Ollama DeepSeek â­â­   Groq Qwen3 32B      Best

â­ = Most efficient for that language
Note: Qwen3 is 3x more token-efficient for CJK (Chinese/Japanese/Korean)
      DeepSeek is best at code-mixing (mixing languages)
```

---

## Confidence Thresholds

```
                    ESCALATE  DISCLAIMER   ACCEPTABLE
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pre-Arrival         < 0.50    < 0.60      > 0.70
Check-In            < 0.40    < 0.55      > 0.60  â† Strictest
During Stay         < 0.50    < 0.70      > 0.80  â† Relaxed
Checkout            < 0.45    < 0.60      > 0.65
Post-Checkout       < 0.50    < 0.65      > 0.75

Calculation: Use 10-message rolling average, not single score
Trend: Escalate if score declining for > 2 minutes
```

---

## Template Comparison

```
TEMPLATE       COST    LATENCY   ACCURACY   BEST FOR
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
T1: Single     Medium  Medium    Good       Low-volume, simple
T2: +Fallback  Med-Hi  Med-Slow  Excellent  Pre-arrival, quality needed
T3: Split      Low     Fast      OK*        High-volume, cost critical
T4: Tiered     Low     Medium    Excellent  â­ Best balance

*T3: 90% from fast tier, only complex intents use expensive model

COST BREAKDOWN (per 500 messages):
  T1: $56.25/day   â† Current
  T2: $67.50/day   (20% overhead for fallback)
  T3: $18.75/day   (67% cheaper but accuracy trade-off)
  T4: $3.30/day    â­ 93% cheaper, same accuracy
```

---

## Intent-Based Token Budget

```
INTENT                    TOKENS   ROUTING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Static (greeting, thanks)   10     No LLM needed
WiFi, pricing, directions   20     Lookup-based
Payment info                50     Template-based
Availability query         200     Hybrid (time calculation)
Late checkout request      150     Hybrid (policy check)
Booking workflow           400     Full LLM + workflow
Complaint, escalation      300     Empathetic LLM response
General question           200     Fallback LLM

Total daily budget: 100,000 tokens for 500 messages
Average per message: 200 tokens (using T4 tiered)
```

---

## Cost Optimization Checklist

```
âœ“ Use tiered-hybrid pipeline (T4)
  â†’ Fuzzy tier catches 90% (0 cost)
  â†’ Semantic tier catches 8% (10 tokens)
  â†’ LLM tier catches 2% (150+ tokens)

âœ“ Phase-aware context sizing
  â†’ Check-in: 4 classify messages (vs 10)
  â†’ Result: 20% reduction in input tokens

âœ“ Language-aware providers
  â†’ Qwen for Chinese (3x token efficiency)
  â†’ Result: 67% token reduction for CJK guests

âœ“ Confidence trend tracking
  â†’ Escalate early on declining trend
  â†’ Result: Fewer wasted tokens on failing paths

Combined Impact: 93% cost reduction ($56/day â†’ $3/day)
```

---

## Decision Tree: Which Template to Use?

```
START
  â†“
Is this a HIGH-VOLUME deployment (>1000 msg/day)?
  â”œâ”€ YES  â†’ Is accuracy critical?
  â”‚        â”œâ”€ YES  â†’ Use T4 (Tiered-Hybrid)
  â”‚        â””â”€ NO   â†’ Use T3 (Split-Model)
  â””â”€ NO   â†’ Use T1 (Single-Model) or T2 (+Fallback)

Guest Journey Phase?
  â”œâ”€ Pre-Arrival    â†’ T2 (quality > speed)
  â”œâ”€ Check-In       â†’ T4 (cost + speed)
  â”œâ”€ During Stay    â†’ T4 (cost efficiency)
  â”œâ”€ Checkout       â†’ T3 (speed needed)
  â””â”€ Post-Checkout  â†’ T1 (simplest)

Cost Budget Constraint?
  â”œâ”€ < $10/day      â†’ T4 or T3
  â”œâ”€ < $20/day      â†’ T2 or T4
  â””â”€ > $50/day      â†’ T1 is fine
```

---

## Phase Detection Rules

```
DETECT PRE-ARRIVAL IF:
  â€¢ Intent = booking, availability, pricing, checkin_info
  â€¢ No check-in time recorded yet
  â€¢ TTL = 72 hours

DETECT CHECK-IN IF:
  â€¢ Intent = check_in_arrival, card_locked, lower_deck_preference
  â€¢ Time = within 2 hours of check-in time
  â€¢ TTL = 4 hours
  â†’ URGENT: Escalate quickly on low confidence

DETECT DURING-STAY IF:
  â€¢ Time = after check-in, before check-out
  â€¢ Intent = any service request (wifi, complaint, etc.)
  â€¢ TTL = 24 hours

DETECT CHECKOUT IF:
  â€¢ Intent = checkout_info, checkout_procedure, late_checkout_request, luggage_storage
  â€¢ Time = near estimated check-out time
  â€¢ TTL = 30 minutes â†’ 2 hours

DETECT POST-CHECKOUT IF:
  â€¢ Intent = post_checkout_complaint, forgot_item, billing_inquiry, review_feedback
  â€¢ Time = after check-out time
  â€¢ TTL = 14 days
```

---

## Escalation Decision Matrix

```
                     CONFIDENCE  REPEAT  ACTION
                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pre-Arrival          < 0.50      Any     Escalate
                     < 0.60      3+      Add disclaimer
                     > 0.70      Any     Auto-reply

Check-In (URGENT!)   < 0.40      Any     Escalate FAST
                     < 0.55      Any     Add disclaimer + escalate
                     > 0.60      Any     Auto-reply

During Stay          < 0.50      Any     Escalate
                     < 0.70      3+      Escalate
                     > 0.80      Any     Auto-reply

Checkout             < 0.45      Any     Escalate
                     < 0.60      Any     Add disclaimer
                     > 0.65      Any     Auto-reply

Post-Checkout        < 0.50      Any     Consider escalation
                     < 0.65      Any     Add disclaimer
                     > 0.75      Any     Auto-reply

TREND-BASED:         Declining   2min+   Escalate regardless of score
```

---

## Multilingual Quick Tips

```
WHAT THE GUEST SAYS          LANGUAGE    PROVIDER TO USE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Hello, how much?"           English     Groq Llama 70B
"Berapa harga bilik?"        Malay       Groq Qwen3 32B â­
"æˆ¿é—´å¤šå°‘é’±?"              Chinese     Groq Qwen3 32B â­
"eh bro wifi pass apa?"      Code-mix    Ollama DeepSeek â­â­

CODE-MIXING RED FLAGS:
  â€¢ "eh bro" (English slang + Malay context)
  â€¢ "boleh ke" (Malay + English question pattern)
  â€¢ "why lah" (English + Malay particle)
  â†’ Route to high-capability model

TOKEN EFFICIENCY:
  English:   1.0x efficiency
  Malay:     1.2x efficiency (Qwen trained on it)
  Chinese:   3.3x efficiency (native CJK tokenization in Qwen)
  Code-mix:  1.5x efficiency (requires better model)
```

---

## Settings.json Key Values

```json
{
  "classify_temperature": 0.1,      // Deterministic, precise
  "chat_temperature": 0.7,           // Natural, friendly
  "max_classify_tokens": 150,        // Intent classification
  "max_chat_tokens": 800,            // Response generation
  "per_minute": 20,                  // Default rate limit
  "per_hour": 100,                   // Default rate limit
  "tieredPipeline": true,            // Enable T4
  "splitModel": false                // Disable T3 by default
}
```

---

## Monitoring Dashboard Essentials

```
REAL-TIME (Update every 10 seconds):
  â€¢ Active sessions right now
  â€¢ Messages processed (queue depth)
  â€¢ Current response latency (P95)
  â€¢ Error rate

PHASE BREAKDOWN (Update every 5 minutes):
  Pre-Arrival:    X conversations, avg confidence Y.Z
  Check-In:       X active sessions, Y escalated/min
  During Stay:    X conversations, avg 5.2 messages each
  Checkout:       X active, 100% using T3 (fast path)
  Post-Checkout:  X conversations, 5 new this hour

COST TRACKING (Update every hour):
  Daily spend so far: $X.XX
  Cost per message: $Y.YY
  Provider usage: Groq 40%, Ollama 35%, DeepSeek 25%
  Template: T4 (tiered) 85%, T1 5%, T2 10%

ALERTS:
  ğŸ”´ CRITICAL: Escalation rate > 15% for any phase
  ğŸŸ¡ WARNING: Avg confidence < 0.65
  ğŸŸ¡ WARNING: Response time P95 > 5000ms
  ğŸŸ¡ WARNING: Error rate > 1%
```

---

## Common Mistakes to Avoid

```
âŒ DON'T: Use same context size for all phases
   âœ“ DO:  Use phase-aware context (4-10 classify, 10-20 chat)

âŒ DON'T: Escalate on single low confidence score
   âœ“ DO:  Use 10-message rolling average + trend detection

âŒ DON'T: Use same rate limits for check-in as during-stay
   âœ“ DO:  Check-in 30/min, during-stay 20/min

âŒ DON'T: Send Chinese queries to generic models
   âœ“ DO:  Use Qwen3 for Chinese (3x token efficiency)

âŒ DON'T: Use expensive LLM for every message
   âœ“ DO:  Use T4 tiered-hybrid (90% zero-cost tier 1)

âŒ DON'T: Apply same confidence threshold everywhere
   âœ“ DO:  Check-in 0.40, during-stay 0.80

âŒ DON'T: Ignore code-mixing in Malay/English regions
   âœ“ DO:  Detect code-mixing, route to DeepSeek

âŒ DON'T: Skip state persistence
   âœ“ DO:  Use Redis for 7-day conversation recovery
```

---

## Implementation Priority

### Week 1 (No Code Changes)
- [ ] Read OPTIMAL-CONFIGURATION-STRATEGY.md sections 1-3
- [ ] Update settings.json with recommended values
- [ ] Enable phase-aware rate limiting in config
- [ ] Increase check-in limit to 30/min

### Week 2-3 (Code Implementation)
- [ ] Implement phase detection in conversation.ts
- [ ] Add confidence trend tracking
- [ ] Set up Redis persistence
- [ ] Add metrics collection

### Week 4-6 (Advanced Features)
- [ ] Language-aware provider selection
- [ ] Code-mixing detection
- [ ] Template selection logic
- [ ] Analytics dashboard

---

## File Locations

```
Configuration Files:
  mcp-server/src/assistant/data/settings.json
  mcp-server/src/assistant/data/llm-settings.json
  mcp-server/src/assistant/data/routing.json
  mcp-server/src/assistant/data/templates.json

Implementation Files:
  mcp-server/src/assistant/ai-client.ts
  mcp-server/src/assistant/message-router.ts
  mcp-server/src/assistant/conversation.ts
  mcp-server/src/assistant/rate-limiter.ts

Documentation:
  docs/OPTIMAL-CONFIGURATION-STRATEGY.md
  docs/CONFIGURATION-IMPLEMENTATION-GUIDE.md
  docs/SETTINGS-CONFIGURATION-REFERENCE.md
  docs/CONFIGURATION-QUICK-REFERENCE.md (this file)
```

---

## TL;DR â€” Key Takeaways

1. **Phase-aware everything** â€” Context, rate limits, confidence thresholds
2. **Use T4 tiered-hybrid** â€” 93% cost reduction vs T1
3. **Qwen for Asian languages** â€” 3x more efficient for Chinese
4. **Trend detection over single scores** â€” 10-message rolling average
5. **Multilingual provider routing** â€” Select by language automatically
6. **Redis persistence** â€” Recover conversations across restarts
7. **Monitor key metrics** â€” Escalation rate, cost/msg, confidence trend

**Expected Impact**: 50-70% cost reduction, similar quality, better UX

---

**Last Updated**: 2026-02-12 | **Version**: 1.0
